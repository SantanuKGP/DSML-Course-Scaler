{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "xDXm4u_m0qXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recap\n"
      ],
      "metadata": {
        "id": "Oau-g4ESVzUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### What have we learned till now?\n",
        "\n"
      ],
      "metadata": {
        "id": "N9w2QW-8_1wG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/086/original/Screenshot_2023-07-31_at_10.27.26_AM.png?1690779929 width=700>"
      ],
      "metadata": {
        "id": "Bpyl_DL5Vvzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What are Decision Trees?\n",
        "- How to build Decision Trees?\n",
        "  - Splitting of nodes\n",
        "  - Entropy to measure impurity\n",
        "  - Information Gain"
      ],
      "metadata": {
        "id": "odq7FYxdV0uU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Issue with Entropy\n",
        "\n"
      ],
      "metadata": {
        "id": "sqo5KnK8UNlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you recall how entropy is calculated?\n",
        "- $H(y) = - âˆ‘_{i=1}^k p(y_i)log(p(y_i))$\n"
      ],
      "metadata": {
        "id": "ponEJDCqV9Mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/087/original/Screenshot_2023-07-31_at_10.27.33_AM.png?1690780005 width=700>"
      ],
      "metadata": {
        "id": "Pe87btXbV5Mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\\\n",
        "So, what's the problem?\n",
        "- Notice that we take log of probability.\n",
        "- We have to do this for each feature, at each node.\n",
        "\n",
        "This is **computationally expensive** and **time consuming**.\n",
        "\n",
        "\\\n",
        "Do we have any alternatives?\n",
        "- That's when **Gini Impurity** comes into picture."
      ],
      "metadata": {
        "id": "4AWNTp89V-eA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0mOkUgKs0sj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "b14fmC3h0u3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Gini Impurity?\n",
        "\n",
        "Similar to entropy, Gini is also\n",
        "- A measure of impurity of nodes.\n",
        "\n",
        "\\\n",
        "#### But how do we calculate Gini Impurity?\n"
      ],
      "metadata": {
        "id": "sLvrymmrTmwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/088/original/Screenshot_2023-07-31_at_10.27.40_AM.png?1690780045 width=700>"
      ],
      "metadata": {
        "id": "JNwP9hFYWDoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take an example to compare **Entropy vs. Gini Impurity**\n",
        "\n",
        "\\\n",
        "Suppose you have a binary classification problem.\n",
        "- $y ~ \\epsilon ~ \\{red, blue\\}$\n",
        "\n"
      ],
      "metadata": {
        "id": "FzFqffO0cz_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/089/original/Screenshot_2023-07-31_at_10.27.49_AM.png?1690780085 width=700>"
      ],
      "metadata": {
        "id": "Z_rnJoMjWNgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing Gini Impurity"
      ],
      "metadata": {
        "id": "MG0Wvbl5N0bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desmos plot: https://www.desmos.com/calculator/yhcwubphxs"
      ],
      "metadata": {
        "id": "GIpsQNPIuAtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=\"https://www.desmos.com/calculator/yhcwubphxs\", width=700, height=375)"
      ],
      "metadata": {
        "id": "LOoCgCeprKSx",
        "outputId": "1922754f-df87-420f-f8ee-582d3f6e4365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f1482a5a110>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"700\"\n",
              "            height=\"375\"\n",
              "            src=\"https://www.desmos.com/calculator/yhcwubphxs\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/090/original/Screenshot_2023-07-31_at_10.27.56_AM.png?1690780130 width=700>"
      ],
      "metadata": {
        "id": "WeqQuBaMWTIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Quiz 1:\n",
        "\n",
        "A decision tree model uses Gini impurity as the splitting criterion.\n",
        "If a node has 60 instances of class A and 40 instances of class B,\n",
        "what is the Gini impurity at that node?\n",
        "\n",
        "A. 0.24\n",
        "B. 0.4\n",
        "C. 0.6\n",
        "D. 0.48\n",
        "\n",
        "Ans: D. 0.48\n",
        "```\n",
        "```\n",
        "Soln:\n",
        "Gini impurity = 1 - (p(A)^2 + p(B)^2)\n",
        "\n",
        "p(A) = 60 / 100 = 0.6\n",
        "p(B) = 40 / 100 = 0.4\n",
        "\n",
        "Gini impurity = 1 - (0.6^2 + 0.4^2)\n",
        "= 1 - (0.36 + 0.16)\n",
        "= 1 - 0.52\n",
        "= 0.48\n",
        "\n",
        "Therefore, the Gini impurity at that node is 0.48.\n",
        "```"
      ],
      "metadata": {
        "id": "eN9EbPApM1OW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How do we calculate Information Gain for Gini Impurity?\n",
        "\n",
        "$IG = GI_{parent~node} - Weighted~GI_{child~nodes}$"
      ],
      "metadata": {
        "id": "RBnc1SoVail5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra reading material\n",
        "\n",
        "Functions for calculating...\n",
        "- Gini impurity\n",
        "- Weighted gini impurity\n",
        "- Information Gain using gini impurity\n",
        "\n",
        "Link: https://colab.research.google.com/drive/1Cf6Bt6sQVYBbvnhtR3cPQENUO4DRGjMP"
      ],
      "metadata": {
        "id": "lBzcFeh1sSd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/091/original/Screenshot_2023-07-31_at_10.28.04_AM.png?1690780165 width=700>"
      ],
      "metadata": {
        "id": "fSHxHCQLWmC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Q0q8DBzI0x4H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wrwHyIOotR"
      },
      "source": [
        "## How to split on numerical features?\n",
        "\n",
        "I hope you remember that our data contains both,\n",
        "- Categorical features\n",
        "- Numerical features\n",
        "\n",
        "\\\n",
        "We already know that for Categorical feature,\n",
        "- DT splits data based on distinct categories."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/092/original/Screenshot_2023-07-31_at_10.28.12_AM.png?1690780208 width=700>"
      ],
      "metadata": {
        "id": "9iyGbjY-Wr6s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC1hYpFMPyWu"
      },
      "source": [
        "#### What happens when we have a Numerical feature?\n",
        "\n",
        "DT uses a **threshold-based approach**.\n",
        "\n",
        "  - Consider a numerical feature $f_1$ with $n$ different values.\n",
        "  - We select a threshold value (say $n_i$) that splits the data into two subsets.\n",
        "  - This is done on the basis of a condition such as:\n",
        "    - $f_1 < n_i$\n",
        "    - $f_1 > n_i$\n",
        "    - $f_1 = n_i$\n",
        "\n",
        "\\\n",
        "#### But how do we choose the threshold?\n",
        "\n",
        "The goal is to find the $threshold+condition$ that gives us **maximum information gain** after splitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Jrc3qynYXCXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/093/original/Screenshot_2023-07-31_at_10.28.20_AM.png?1690780248 width=700>"
      ],
      "metadata": {
        "id": "Hvq9YfZLW3gT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Arrange the values in $f_1$ in increasing order\n",
        "2. Set each value of $f_1$ i.e. ($n_1$, $n_2$, $n_3$,..) as threshold\n",
        "3. Calculate the IG of the split for all values"
      ],
      "metadata": {
        "id": "-0g9_zxiXDQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/094/original/Screenshot_2023-07-31_at_10.28.26_AM.png?1690780348 width=700>"
      ],
      "metadata": {
        "id": "NEdkFvJDXFTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. Which gives us $n$ IG values say IG$_1$, IG$_2$, IG$_3$ ... IG$_n$\n",
        "5. Choose whichever threshold gives the highest IG."
      ],
      "metadata": {
        "id": "l1-aYf1EXFiL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kAgu9RBV19i"
      },
      "source": [
        "#### But what if two features yield equal IG?\n",
        "  - In such case,\n",
        "    - We can never know for sure which feature would be the best.\n",
        "    - So we can randomly select any feature to split the node."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you see any problem in splitting on numerical features?\n",
        "\n",
        "\\\n",
        "**Time Complexity**\n",
        "  - For a feature with 1000 different values,\n",
        "  - We have to compute 1000 different splits.\n",
        "  - This is very unefficient.\n",
        "\n",
        "\\\n"
      ],
      "metadata": {
        "id": "6JIm6vzjF4Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How can we make it more efficient?\n",
        "\n",
        "By binning the feature values.\n",
        "  - Suppose we have an `Age` column.\n",
        "    - Range: [20, 60]\n"
      ],
      "metadata": {
        "id": "VPRub1IaXcQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/095/original/Screenshot_2023-07-31_at_10.28.37_AM.png?1690780522 width=700>"
      ],
      "metadata": {
        "id": "AKnZHcCDXdXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  - We can bin the values into `Age Groups`.\n",
        "    - Bins: [20, 30), [30, 40), [40, 50), [50, 60]"
      ],
      "metadata": {
        "id": "sbvGRQfAXdn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dq7-9yag02Sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfit Vs Underfit\n"
      ],
      "metadata": {
        "id": "5DY4UhX5YA48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Recall in the last lecture we calculated the train & test accuracy for our DT -\n",
        "\n",
        "- Accuracy -\n",
        "  - Train: 1.0\n",
        "  - Test: 0.76\n"
      ],
      "metadata": {
        "id": "aPIXEuNQYDLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/096/original/Screenshot_2023-07-31_at_10.28.44_AM.png?1690780545 width=700>"
      ],
      "metadata": {
        "id": "FleZP1PKX915"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "#### What can we conclude from this?\n",
        "\n",
        "- There's a big difference in training & test accuracy.\n",
        "- It means, the DT model is **overfitting** the data.\n",
        "\n",
        "\\\n",
        "#### When do you think a DT will **overfit**?\n",
        "\n",
        "If all the leaf nodes are pure then,\n",
        "- the DT would have 100% accuracy on training set."
      ],
      "metadata": {
        "id": "4KFITXUUYE5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "#### Why does DT overfit as the depth increases?\n",
        "\n",
        "Imagine we have 1000 data points.\n",
        "- as the depth increases, the data set becomes smaller.\n",
        "\n",
        "By the time we reach the leaf node,\n",
        "- there will be fewer points.\n",
        "- these points coule be noise/outliers."
      ],
      "metadata": {
        "id": "AYPHXV2XYPw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/097/original/Screenshot_2023-07-31_at_10.28.51_AM.png?1690780598 width=700>"
      ],
      "metadata": {
        "id": "5bpe9nR5YJ3r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgABfTXDWUzf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This results in **Overfitting**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How can we resolve this problem?\n",
        "  \n",
        "  - Stop splitting nodes before they become pure.\n",
        "  - Or in simpler terms, by reducing the **Depth of the DT**."
      ],
      "metadata": {
        "id": "3qSGLqTQxXK-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncN1il-6ZuMH"
      },
      "source": [
        "#### But what if the depth is too low?\n",
        "\n",
        "\\\n",
        "Typically, we let the tree grow until we get a pure node.\n",
        "\n",
        "What if we stop the tree growth at a depth=2?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This would mean...\n",
        "- Lot of -ve points might also fall in that leaf node,\n",
        "- and they'll be incorrectly classified as +ve.\n",
        "\n",
        "\\\n",
        "This results in **Underfitting**.\n",
        "\n",
        "\\\n",
        "If the tree depth is less,\n",
        "- it means the splits are less.\n",
        "\n",
        "Hence, **number of hyper-planes dividing the data space are less** </br> i.e., less variance and more bias."
      ],
      "metadata": {
        "id": "RWhU4a4s4ZSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "\n",
        "- A **deep tree** usually Overfits the training data.\n",
        "- A **shallow tree** usually Underfits the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "kUMiom9bCzoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/041/098/original/Screenshot_2023-07-31_at_10.28.58_AM.png?1690780751 width=700>"
      ],
      "metadata": {
        "id": "i7nm-JEHYold"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5p2GUZFPRB"
      },
      "source": [
        "### Tradeoff\n",
        "\n",
        "#### How do we find the right depth of our DT?\n",
        "\n",
        "Our goal is to -\n",
        "- not overfit outliers\n",
        "- not underfit training samples\n",
        "\n",
        "\\\n",
        "The idea here is to -\n",
        "- treat **depth** as a hyperparameter\n",
        "- and find its optimal value."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "asHxBu2F08c7"
      }
    }
  ]
}