{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "- Introduction\n",
        " - What is a recommendation system?\n",
        " - How do we formulate a rec sys problem?\n",
        " - How can we represent the dataset for rec sys?\n",
        "- Collaborative Filtering\n",
        "- Similarity based approaches\n",
        "  - Item-item based similarity\n",
        "  - User-user based similarity\n",
        "  - Cold start problem\n",
        "- Content based Rec Sys\n",
        "- Recommendation as a Regression/Classification problem\n",
        "- Types of Rec Algos"
      ],
      "metadata": {
        "id": "Wqk5naWN5zIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "t0oHyAI255HO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q. What is a recommendation system/engine?\n",
        "A recommender system is a system which predicts ratings a user might give to a specific item.\n",
        "\n",
        "These predictions will then be ranked and returned back to the user as rcommendations.\n",
        "\n",
        "The goal of a good recommmender engine is to hook the user to the platform.\n",
        "\n",
        "There are many apps that we use that make use of recommendation systems. Example:\n",
        "- Netflix\n",
        "- Tiktok\n",
        "- Amazon\n",
        "- Youtube\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How have recommender systems evolved over time?**\n",
        "\n",
        "- **Pre 2007**\n",
        " - **Similarity based**\n",
        " - **Content based**\n",
        " - **Collaborative Filtering** algorithms were used\n",
        "\n",
        "- **2007 - 2015**\n",
        " - In 2007, **Netflix** held a competition where it promised a prize of million dollars to the team of people that can improve their recommendation engine.\n",
        " - The winning team had their solution based on the concept of **Matrix Factorization**, which became popular in this period.\n",
        "\n",
        "- **Post 2015**\n",
        " - **Deep learning** algorithms are being used now.\n",
        "\n",
        "![image](https://docs.google.com/uc?id=16kDmFNdeSUPoS4HyaC_AamF1ke7i7DvG)\n"
      ],
      "metadata": {
        "id": "0OqLS7koMzjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q. How do we formulate a recommender system problem?\n",
        "The problem formulation here is different than what we've seen already for Classification or regression.\n",
        "\n",
        "Suppose we have $n$ users, $U_i; i=[1, n]$ and $m$ items (product on amazon, movie on Netflix, song on spotify, etc), $I_j; j=[1,m]$.\n",
        "\n",
        "`Goal:`\n",
        "- We need to suggest a list of items to user $U_i$ that he/she will like.\n",
        "- These items should be ranked (preferably).\n",
        "- This is of course, based on historical data.\n",
        "\n",
        "**NOTE:** Naturally, m would be in billions, whereas we can have millions of users (n). The point is, that the **scale is very large**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1aSnd1pGoS6dOHVMi3p_py-9SPJ7QU976)"
      ],
      "metadata": {
        "id": "mhN9sush522M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Q. How can we represent the dataset for recommender systems?\n",
        "\n",
        "The dataset is represented in the form of a **matrix**, lets call it `A`.\n",
        "\n",
        "In `A`, each row represents a user $U_i$, and each column represents an item $I_j$. This way, element $A_{ij}$ denotes user $U_i$'s interaction with product $I_j$.\n",
        "\n",
        "This interaction can be measured in many ways, depending on context,\n",
        "- If the youtube video is liked **(Binary value)**.\n",
        "- Percentage of song listened to, in spotify **(real valued)**.\n",
        "- If user spent 2 minuets reading about the product on amazon.\n",
        "- Rating of the Netflix movie **(numeric value)**.\n",
        "- If the product was bought or not.\n",
        "\n",
        "Basically, we try to represent whether user indicated any form of interest in that product.\n",
        "\n",
        "Naturally, `A` is a `n x m` matrix.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. What if user $U_i$ has never interacted with a specific product ,say $I_2$?**\n",
        "\n",
        "When we have billions of products, it is next to impossible for any given user to have interacted with all of them.\n",
        "\n",
        "For example,\n",
        "- A user of Youtube, residing in New Delhi would not have seen any German videos, owing to the language barier.\n",
        "- This leaves the entire section of German videos, that this user has never even interacted with.\n",
        "\n",
        "In such cases, we leave the cell $A_{i2}$, where $I_2$ represents such a German videos, as **empty**.\n",
        "\n",
        "Similarly, a lot of cells would be empty in matrix A.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1HQQpohiU06-jQB7zWZz8FGNrcAmOqfU8)\n",
        "\n"
      ],
      "metadata": {
        "id": "DMg1wHjYULiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that we have about a billion users, $n \\approx 10^9$, and a few hundred million videos of Youtube, which means, $m ≈ 10^8$.\n",
        "\n",
        "This means we have a total of $10^9 * 10^8 = 10^{17}$ cells in matrix A.\n",
        "\n",
        "It is not possible for every user to have watched (or rated) every video on YouTube.\n",
        "\n",
        "Practically, on an average, an user $U_i$ would have interacted with 1000 youtube videos, which is next to nothing in comparison to the total number of videos present.\n",
        "\n",
        "Hence we can say that matrix A is **sparse**.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How do we fix our matrix being sparse?**\n",
        "\n",
        "We don't need to \"fix\" anything.\n",
        "\n",
        "The main goal of building a recommender system is that if a user $U_i$ has given rating, for a few items, then the system should recommend new items based on the user's interests. This IS the problem at hand.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How can we calculate the sparsity of matrix A?**\n",
        "\n",
        "$sparsity = \\frac{Number \\ of \\ non \\ empty \\ cells}{Total \\ No. \\ of \\ cells}$\n",
        "\n",
        "As per our example of Youtube,\n",
        "\n",
        "$sparsity = \\frac{10^9 * 1000}{10^{17}} = 10^{-5}$\n",
        "\n",
        "This means that only 1 in 10<sup>5</sup> cells is not empty in A.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1cn2qXfypJveCvM64vJmyLssMwanT93tL)\n",
        "\n"
      ],
      "metadata": {
        "id": "CtjuRfME44HC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Collaborative Filtering"
      ],
      "metadata": {
        "id": "RRBxW7P49ueU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q. We're just given the A<sub>n x m</sub> matrix, how can we recommend items to users based on this?\n",
        "**Task:** Given A<sub>n x m</sub> , we need to recommend some items to user $U_i$."
      ],
      "metadata": {
        "id": "6y2vfPvn4xGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we dive into this problem, first lets try to retrieve information about the users and the items from the given matrix A.\n",
        "\n",
        "\n",
        "> **Q. How can we obtain an user / item vector from matrix A?**\n",
        "\n",
        "We're just given the matrix A<sub>n x m</sub>, and we wish to obtain some representation of data for a user $U_i$.\n",
        "\n",
        "Recall that for text data, we form a bag of words representation (BoW), which works as our features.\n",
        "\n",
        "Similarly, we can have a vector of dimension $m$ x $1$, where each element would tell if user $U_i$ has bought/watched (shown interest in) item j, such that $j ϵ [1, m]$.\n",
        "\n",
        "For cases where user $U_i$ has not interacted with / shown interest in item $I_j$, we can simply put 0.\n",
        "\n",
        "This is a very crude approach, but this way we can have a user data.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1NbAvRsl8In3WuJhk_6TEeXfVr_6GKLcI)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "If you think about it, this is essentially the ith row of matrix A.\n",
        "\n",
        "Similarly, we can also get a $n$ x $1$ vector that represents data for an item $I_j$, which would be the jth column of matrix A.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1r4Gk3pqEFfWxbg40nFlW9Z01S8GVc1v7)\n",
        "\n",
        "This way of using the given matrix A to form user and item vectors is known as **Collaborative filtering (CF)** reccomendation system.\n",
        "\n",
        "Lets take a look at different approaches we can adopt to implement CF Recommendation systems.\n"
      ],
      "metadata": {
        "id": "Kwr5hYNQAezk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Item-Item based Similarity"
      ],
      "metadata": {
        "id": "9-5QosU_4EN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already have historical data about the items bought (positively rated) by a user $U_i$.\n",
        "\n",
        "Let's say that this user has already bought item $I_{10}$ and $I_{12}$\n",
        "\n",
        "> **Q. What if we find an item $I_j$ that is similar to these already bought items?**\n",
        "\n",
        "This is a good idea.\n",
        "\n",
        "We can find items with high similarity to the items historically bought by user $U_i$ ($I_{10}$ and $I_{12}$), as we know that this user showed interest in such items.\n",
        "\n",
        "\n",
        "For example,\n",
        "- If a user of Spotify likes music by Lata Mangeshkar, there is a high chance he/she will like songs by Asha Bhosle also.\n",
        "- If a user of Netflix likes Mission Impossible 2, there is a high chance he/she will like other action movies like John Wick.\n",
        "\n",
        "There is a sense of similarity among these items.\n",
        "\n",
        "In our case,\n",
        "- since our user $U_i$ likes $I_{10}$ and $I_{12}$,\n",
        "- we need to find set of items similar to both $I_{10}$ and $I_{12}$\n",
        "- If an item $I_k$ lies in both these sets, there is more chances of user $U_i$ liking item $I_k$.\n",
        "\n",
        "This is like the **Nearest Neighbour** based approach.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How can we find similarity between different items?**\n",
        "\n",
        "Every $I_j$ is a n dimensional vector. It represents the ratings given to item $I_j$ by all the n users.\n",
        "\n",
        "So, we use **cosine similarity** metric to measure the similarity between a specific item say $I_{10}$ and rest of the items.\n",
        "\n",
        "Based on this metric value, we recommend the items that are most similar to $I_{10}$.\n",
        "\n",
        "$sim(I_i, I_j) = cosine \\ similarity(I_i, I_j) = \\frac{I_i ^T * I_j}{||I_i|| * ||I_j||} = S_{ij}$\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1GS4UyFjq2dN-YullCGZd9P1euM48eT0T)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How can we store these similarity scores?**\n",
        "\n",
        "We build a **similarity matrix**, with all the $S_{ij}$ values.\n",
        "\n",
        "Since we're talking about item-item similarity, we denote this matrix as $S^i$.\n",
        "\n",
        "The dimensions of $S^i$ becomes $m$ x $m$, and $S_{ij}^i$ represents how similar two items $I_i$ and $I_j$ are.\n",
        "\n",
        "Larger the value of $S_{ij}^i$, more similar items $I_i$ and $I_j$ are.\n",
        "\n",
        "TODO: Scribble showing similarity matrix\n",
        "\n",
        "<br>\n",
        "\n",
        "This is known as **Item-Item based Collaborative Filtering**  Recommender system. It was introduced by **Amazon** in 1998.\n",
        "\n",
        "Here, the recommender engine compares the items that are already positively rated by a user, with the items that he did not rate and looks for similarities.\n",
        "\n",
        "Items similar to the positively rated ones will be recommended.\n",
        "\n",
        "**NOTE:**\n",
        "- This is one of the most basic ideas behind YouTube recommendation engine.\n",
        "- There is a lot of added layers of complexity on top of this, but this is the idea.\n",
        "\n",
        "<br>\n",
        "\n",
        "The dimensions of the item-item similarity matrix is $m$ x $m$, and m is a very large number.\n",
        "\n",
        "> **Q. Wouldn't the calculation of the similarity matrix be a very time consuming process?**\n",
        "\n",
        "Yes. This would be very time consuming.\n",
        "\n",
        "Back in the day, when this approach was used in platforms like Amazon, We could not afford to do spend so much time on the go, as the user logs in.\n",
        "\n",
        "So, this calculation did not took place when the user logs in, rather it was performed during the nights, or maybe even weekly, so that when user logs in, they readily get the recommendations based on this calculation.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1hZWWGQHJL08dIoWWox8TngqexalbFquu)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2NqyakCy4LwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User-User based similarity"
      ],
      "metadata": {
        "id": "7yzhyIFTOJL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a user $U_i$.\n",
        "\n",
        "> **Q. What if we find a user $U_j$ that is similar to $U_i$?**\n",
        "\n",
        "Since we know both these users are similar, we can use the history of one user to give recommendations to the other.\n",
        "\n",
        "We already have a $m$ x $1$ vector representing user data for ith user, that we retrieved from A, $U_i$.\n",
        "\n",
        "Using **cosine similarity** we can find similarity between user $U_i$ and all the others, to find the most similar users.\n",
        "\n",
        "Here also, this data is formed in the form of a **similarity matrix** $S^u$, where $S_{ij}^u$ represents how similar user $U_i$ is to user $U_j$.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1gIo0rnPPZgYHmJDF6Rpgw54jKWh_5r5_)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Using cosine similarity, we can find the most similar users, what now? How do we use this to recommend items to user $U_i$?**\n",
        "\n",
        "Consider that user $U_i$ has already bought items $I_{10}$ and $I_{18}$.\n",
        "\n",
        "Using cosine similarity, we find that users $U_{10}, U_{26}, U_{58}$ are similar to user $U_i$. Their purchase history includes:-\n",
        "- $U_{10}$: $I_{10}$, $I_{12}$, $I_{18}$, $I_{20}$\n",
        "- $U_{26}$: $I_{10}$, $I_{18}$, $I_{26}$, $I_{12}$\n",
        "- $U_{58}$: $I_{18}$, $I_{12}$\n",
        "\n",
        "User $U_i$ has already bought items $I_{10}$ and $I_{18}$.\n",
        "\n",
        "Using a **frequency based** approach, we can say that item $I_{12}$ seems to be very popular among the other similar users ($U_{10}, U_{26}, U_{58}$), we can guess that user $U_i$ might also be interested in buying $I_{12}$, making it a good recommendation!\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=10sy_RR9__4hswrL8uyG-NNJR42Ehej8-)\n",
        "\n",
        "<br>\n",
        "\n",
        "This technique, where we find similar users is called **User-User similarity based Collaborative Filtering**.\n",
        "\n",
        "**NOTE:**\n",
        "- This approach is also similar to Nearest Neighbour approach.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Can you think of a flaw in user-user similarity approach?**\n",
        "\n",
        "One major problem with user-user similarity is that **User preferences can change over time**.\n",
        "\n",
        "This can lead to bad recommendations.\n",
        "\n",
        "In order to handle this, we prefer using item-item similarity approach, because in contrast, the ratings on given items do not change significantly over time."
      ],
      "metadata": {
        "id": "Nf44MdSfOO7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Q. How to decide when to use user-user or item-item similarity approach?**\n",
        "\n",
        "Consider the following rule of thumb.\n",
        "\n",
        "When we have more number of users than items, i.e. n > m, and if the item ratings do not change much over time, after the initial period, then it is better to use the item-item similarity approach.\n",
        "\n",
        "<br>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KW_c5vpTzE3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cold Start Problem"
      ],
      "metadata": {
        "id": "AdQXaKSnipn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Q. What if we have a new user joining the platform?**\n",
        "\n",
        "When a new user joins, then we have no ratings given from this user, as he is new to the ecosystem. So, we cannot find similar users.\n",
        "\n",
        "Suppose $U_i$ is a new user. Hence, the cells of ith row in A would be empty.\n",
        "\n",
        "This means that entire user vector has no data.\n",
        "\n",
        "For every recommender system, it is required to build a user profile by considering the user's activities and behaviours with the system.\n",
        "\n",
        "Based on user's history only, recommendations are made.\n",
        "\n",
        "If there is no historical data, that is a problem.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Similarly, what if there is a new product that's added to the platform?**\n",
        "\n",
        "Here again, we have no historical data, as it is a new product.\n",
        "\n",
        "We cannot find any similar items to it.\n",
        "\n",
        "If $I_j$ represents the new item, jth column of A would be empty.\n",
        "\n",
        "This means that entire item vector has no data.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1vR2xZ3AgfRWZq1hyBl38nlKkFQ0fT4U1)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. What is a cold start problem?**\n",
        "\n",
        "Both these cases are called as a **Cold Start Problem**.\n",
        "\n",
        "This arises since we have no data about these new users/items, hence preventing us from being able to give good recommendations.\n",
        "\n",
        "This problem arises due to 3 different reasons:-\n",
        "- For new users\n",
        "- For new items\n",
        "- For new communities\n",
        "\n",
        "In these cases, we don't have enough information to make good decisions/recommendations.\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "8OJApnqxisTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Content based Recommendation System"
      ],
      "metadata": {
        "id": "aTO70bBTay4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Q. How can we overcome cold start problem?**\n",
        "\n",
        "A basic idea would be to recommend the most popular / frequently bought items using a frequency based approach. But this is a very vague approach. Let's think of something else.\n",
        "\n",
        "Consider the case of a new user.\n",
        "\n",
        "Even though we do not have any information regarding this user's interactions with different items, we do have other additional information about this new user.\n",
        "- **Location**\n",
        " - This can be used to get an idea of the items used / purchased by other users in that area.\n",
        " - A swiggy recommender engine can make an assumption that Idli-Dosa are more probable to be liked by a user residing in Southern India.\n",
        " - We can get the location of user from IP Address\n",
        " - Most platforms do ask for your location before letting you sign up.\n",
        "\n",
        "- **Gender**\n",
        " - Useful in recommending clothes and accessories.\n",
        "\n",
        "- **Age**\n",
        "\n",
        "- **Type of Credit Card**\n",
        " - This too can help get a lot of information about the data, like their spending habbits, their credit limit, brand of credit card, etc.\n",
        "\n",
        "- **Device being used to access the platform**\n",
        " - We can assume that an user using Apple Macbook would have more spending power than a user using a cheap Chinese smartphone.\n",
        "\n",
        "We form a new d'-dimensional vector that holds all this data, and then use **user-user similarity** on it, and recommend accordingly.\n",
        "\n",
        "This is known as **User-user similarity based Content Filtering** Recommender systems.\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1_h3afZD7o4PYRpiO3SJ5anALn-Z_1-8H)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Do we have any kind of additional information that can be used in case of a new item cold start?**\n",
        "\n",
        "Yes.\n",
        "\n",
        "Consider that there is a new product on Amazon, though there is no data about user ratings, we still have additional information like:-\n",
        "- **Product description**\n",
        " - This would potentially be stored as a BoW\n",
        "- **Price**\n",
        "- **Category of product**\n",
        " - Like electronics, clothing, sports, etc.\n",
        "... and so on.\n",
        "\n",
        "We form a new d-dimensional vector that holds all this data, and then use **item-item similarity** on it, and recommend accordingly.\n",
        "\n",
        "Hence this is called **item-item similarity based content filtering** Recommender systems.\n",
        "\n",
        "We can recommend this new item to those users who bought similar items from the same categories until we have sufficient information.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1BdcUIWKgog9doqXhOXWc8F-JgSPqJrs-)\n",
        "\n",
        "<br>\n",
        "\n",
        "These additional information is known as **metadata**.\n",
        "\n",
        "This process of finding user-user or item-item similarities, using metadata in order to recommend items to users is called **Content based Recommendation system**.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Why is it called \"Content based\" Recommendation?**\n",
        "\n",
        "Because we are not using the purchase data (the $A_{ij}$s) for finding similarity and then recommending.\n",
        "\n",
        "Instead we are using **features extracted from**/provided in the **content** of the user / item to form d-dimensional vector representing the user/item metadata.\n",
        "\n",
        "The point of content based filtering is that we have to know the content of both the users and the items.\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1jLtzH5t0VkCJLYVPtOFXznvEE2lfrP2a)\n",
        "\n"
      ],
      "metadata": {
        "id": "uRp2aKMCa2R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q. What are some advantages and disadvantages of content based filtering?\n",
        "\n",
        "**Advantages**\n",
        "- The model doesn't need any data about other users, since the recommendations are specific to this user. This makes it **easier to scale** to a large number of users.\n",
        "- The model can capture the specific interests of a user, and **can recommend niche items** that very few other users are interested in.\n",
        "\n",
        "**Disadvantages**\n",
        "- Since the feature representation of the items are hand-engineered to some extent, this technique requires a lot of domain knowledge. Therefore, the model can only be as good as the hand-engineered features.\n",
        "- It always recommends items related to the same categories, and never recommend anything from other categories.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Q. What are some advantages and disadvantages of collaborative filtering?\n",
        "**Advantages**\n",
        "- No domain knowledge necessary\n",
        " - We don't need domain knowledge because the embeddings are automatically learned.\n",
        "- **Serendipity**\n",
        " - The model can help users discover new interests. In isolation, the ML system may not know the user is interested in a given item, but the model might still recommend it because similar users are interested in that item.\n",
        "\n",
        "- The system doesn't need contextual features.\n",
        "\n",
        "**Disadvantages**\n",
        "- Fails in case of cold start."
      ],
      "metadata": {
        "id": "Wbyn3ESqN2BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Recommendation as a Regression/Classification problem"
      ],
      "metadata": {
        "id": "yv25aNZ_DSgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw how we can use the metadata to create d-dimensional user and item feature vectors.\n",
        "\n",
        "> **Q. Can we use these d-dimensional user and item vectors as features, of a Regression/Classification problem?**\n",
        "\n",
        "Suppose that a user $U_i$ gave a rating of 4 to an item $I_j$, i.e. $A_{ij} = 4$.\n",
        "\n",
        "Using metadata, we can obtain a feature vectors for the user $U_i$ and for item $I_j$ of dimension d' and d respectively.\n",
        "\n",
        "If we concatenate these two feature vectors, and put the label as $A_{ij}$, which is the rating given by $U_i$ to $I_j$, we get an entry of data that we can use for training a regression/classification problem.\n",
        "\n",
        "This way, we can form training data from the entries of matrix A, that are non-empty.\n",
        "\n",
        "Here, we're using both, the metadata given to us, and the entries of matrix A, to train a regression/classification problem, and predict the ratings of a new pair of user and item, given their features.\n",
        "\n",
        "Therefore, this becomes a hybrid model of sorts.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1nQaCej8Y31ZBWH0eT1UTY0hPHBPhY22h)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Is there any problem with this approach?**\n",
        "\n",
        "Consider the case when a new user is added.\n",
        "\n",
        "We do not run into a cold start problem, as we can predict ratings of this new user for items, using his/her metadata.\n",
        "\n",
        "But, in order to recommend the top 10 items, we will first have to predict the ratings for **ALL** the items. This is a problem because we can have as many as a million items in real world.\n",
        "\n",
        "So, naturally, doing so would be very very computationally heavy.\n",
        "\n",
        "Hence, this model is not feasible.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=11ZLH5nKnyLK92gaa38jMkyLJNZdLT9EQ)\n"
      ],
      "metadata": {
        "id": "4P2BrTZbDXoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Summary: Types of Recommendation Algorithm"
      ],
      "metadata": {
        "id": "-E0wG-kybyn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classical Recommender systems can be broken down into following types:-\n",
        "1. Content based\n",
        " - Uses content based features like location, gender, etc\n",
        " - Very helpful in cold start problems\n",
        "2. Collaborative filtering\n",
        " - Uses the data given in matrix A, i.e. the $A_{ij}$ values\n",
        " - Unlike content based filtering, we don't need to hand-engineer the features.\n",
        "3. Hybrid models\n",
        " - Uses both content based features and  the $A_{ij}$ values\n",
        "\n",
        "**Note:**\n",
        "- Both user-user and item-item based similarity approaches can be adopted for both, content based and collaborative filtering techniques.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1o0dHtVRrI6mAcw2mn9tw7MTLIxYONCoK)\n"
      ],
      "metadata": {
        "id": "JZWafqjob8JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Matrix Factorization (MF)"
      ],
      "metadata": {
        "id": "LCYVzRLJr_Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the concept of factorization in algebra, that you'd have studied in school.\n",
        "\n",
        "As per this concept, we can write a number as products of it's **factors**. For example, $6 = 2 * 3$.\n",
        "\n",
        "Recall that we have our $n$ x $m$ matrix A.\n",
        "\n",
        "Let's try to expand this concept for matrices by decomposing it as a product of two other matrices:-\n",
        "\n",
        "A<sub>n x m</sub> = B<sub>n x d</sub> . C<sub>d x m</sub>\n",
        "\n",
        "This is called as **Matrix Factorization (MF) / Matrix Decomposition**\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Can we factorize matrix A into a product of 3 matrices?**\n",
        "\n",
        "Yes.\n",
        "\n",
        "Just as 12 can be written as both $12 = 2*6$ and $12=2*3*2$, we can similarly decompose matrix A into 3 factor matrices instead of 2.\n",
        "\n",
        "The final dimensions should match with $n$ x $m$. If that is taken care of, then we can factorize A into even more factors.\n",
        "\n",
        "A<sub>n x m</sub> = B<sub>n x d</sub> . C<sub>d x d'</sub> . D<sub>d' x m</sub>\n",
        "\n",
        "But, In context of Recommender systems, decomposition into 2 factor matrices is done.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1ZZ7AAx4WrK4gcKm2lvnXLM4wEt7rLs6p)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How is the concept of MF relevant to Recommender systems?**\n",
        "\n",
        "Recall that our matrix A is very sparse, which means that there are a lot of missing values.\n",
        "\n",
        "If we could approximately complete this matrix based on the values that we do have, we would essentially get an idea of how each user would rate each item. This would be very helpful in recommending new items to the users.\n",
        "\n",
        "This technique of utilising the available values to complete the sparse matrix A is called **Matrix Completion**.\n",
        "\n",
        "There are tonnes of ways to solve the problem of Matrix Completion, one way of achieving this is by the process of **MF**.\n",
        "\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=13Oe-MaTwTBY4Yx4r_NvHNmgheQ5Orb5c)\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1EV7IHts9dj-1AtLsGWDMNReo5wPF3Kaf)"
      ],
      "metadata": {
        "id": "KdnYt0_vsCw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Q. What is the underlying assumption behind Matrix Factorization in Recommender systems?**\n",
        "\n",
        "The fundamental assumption of Matrix Factorization based Recommender systems is that $A_{ij}$, i.e. the user $U_i$'s rating for an item $I_j$ can be decomposed as a dot product between an user vector $B_i$ and an item vector $C_j$.\n",
        "\n",
        "This idea of using Matrix Factorization for Recommender systems was introduced around 2008-2009, during the **Netflix prize competition**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1CDcassowMBPLGITbNH0v0Om6470rcaSY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Woe1RkFqlVC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Q. How can we go about completing the given matrix A using MF?**\n",
        "\n",
        "Consider the matrix A. Even though we don't all of it's values as it is sparse.\n",
        "\n",
        "Let's assume the following decomposition to be true: A<sub>n x m</sub> = B<sub>n x d</sub> . C<sup>T</sup><sub>d x m</sub>,\n",
        "where <br>\n",
        "n -> No of users <br>\n",
        "m -> No of items\n",
        "\n",
        "\n",
        "C has dimensions: $m$ x $d$, but in order to take a dot product, we need to take transpose, so that dimensions match with those of B<sub>n x d</sub>\n",
        "\n",
        "This is known as an **Interaction model**, we will see why it's called that in a bit.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1ReFOAT3Zc7STUPyNqi1mdSvZjlhEqxjp)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Q. How can we represent the value of a cell $A_{ij}$ in terms of matrices B and C?\n",
        "\n",
        "Look at how B and C matrix look like in the figure above.\n",
        "\n",
        "We can obtain $A_{ij}$ by doing a dot product of the ith row of matrix B and the jth row of matrix C.\n",
        "\n",
        "Let's obtain these rows in form of vectors. Recall that Whenever we write a vector, we say its a column vector.\n",
        "\n",
        "So, we get $B_i$ and $C_j$ as the required column vectors respectively.\n",
        "\n",
        "Hence, in order to do a dot product, we need to a transpose of $B_i$.\n",
        "\n",
        "\n",
        "$A_{ij_{1 x 1}} = B_{i_{1 x d}}^T . C_{j_{d x 1}}$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Notice that our original matrix B had a dimension of $n$ x $d$, where n represents the no of users.\n",
        "\n",
        "So we can interpret $B_i$ to be a d-dimenisonal vector that represents user $U_i$.\n",
        "\n",
        "Similarly, $C_j$ can be thought of as a d-dimensional vector that represents the item $I_j$\n",
        "\n",
        "TODO: Scribble 2\n",
        "![picture](https://drive.google.com/uc?export=view&id=1yiNaCGWOfyrf0UhlA3yVIycBlfOECmWw)\n",
        "\n",
        "**NOTE:**\n",
        "- Multiplication in linear algebra is also known as \"Interaction\", hence we call this model as the **Interaction Model.**\n"
      ],
      "metadata": {
        "id": "tl3rH0rpEbE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see we're getting $A_{ij}$, i.e. the user $U_i$'s rating for an item $I_j$ by the interaction (dot product, to be exact) between $B_i$ and $C_j$ vectors, that represent the user $U_i$ and item $I_j$ repectively.\n",
        "\n",
        "This is the assumption we had made in the beginning of MF.\n",
        "\n",
        "$A_{ij_{1 x 1}} = B_{i_{1 x d}}^T . C_{j_{d x 1}}$\n"
      ],
      "metadata": {
        "id": "E8CveG6bjlmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Q. How can we find the $B_i$ and $C_j$ vectors, even though we only have a few $A_{ij}$ values in the rating matrix?\n",
        "\n",
        "Suppose that $n=10,000$ and $m=1,000$\n",
        "\n",
        "This means total number of cells in A = $10^4 * 10^3 = 10^7$\n",
        "\n",
        "Since A is sparse, lets assume that out of these $10^7$ cells, only $10^5$ are non-empty.\n",
        "\n",
        "**Task:** Given a small subset of $A_{ij}$ values, we want to compute d-dimensional vectors $B_i$ for all users ($i -> [1, n]$), and $C_j$ for all items ($j -> [1,m]$).\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=13j1uVjf7_82DJ8V_kOIQBOzlePhJnPrQ)\n",
        "\n",
        "\n",
        "Though we don't know what $B_i$ and $C_j$ are, we want their product to be as close as possible to $A_{ij}$, for all the **non-empty** entries in A.\n",
        "\n",
        "$A_{ij} ≈ B_{i_{1 x d}}^T . C_{j_{d x 1}}$\n",
        "\n",
        "We can translate this in the form of **Mean Squared Loss**. We'd like to minimise that for all the cells that are **non-empty** in A\n",
        "\n",
        "$min_{B_i, C_j} Σ (A_{ij} - B_i^T . C_j)^2$\n",
        "\n",
        "This becomes our **optimization problem** for MF based Rec Sys.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1_hgbqyK2jrBoMvWctc5-kym3-A0XU7sn)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How can we solve the optimization problem of MF based Rec Sys?**\n",
        "\n",
        "There are broadly 2 approaches to solve this:-\n",
        "1. **Stochastic Gradient Descent (SGD)**\n",
        " - Randomnly assign values in $B_i$ and $C_j$ and perform SGD\n",
        " - This will take time as there are huge number of users and items.\n",
        "2. **Coordinate Descent Algorithms**\n",
        " - We consider $B_i$ and $C_j$ as separate coordinates\n",
        " - We fix $B_i$ for a few iterations and update $C_j$.\n",
        " - Then, we fix $C_j$ and update $B_i$ for a few iterations.\n",
        " - This is repeated untill they converge to solve the optimization problem.\n",
        " - This techinque is also known as **Alternating Least Squares (ALS)**\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=14fJvxyl_ntBtxSX9htJed3ql6Tq7mwL_)"
      ],
      "metadata": {
        "id": "53yu-lpEo5Ft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, using the non-empty cells of matrix A along with the optimization technique, we're able to find suitable values for $B_i$ and $C_j$.\n",
        "\n",
        "Recall that this was the primary goal of this entire exercise.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How can we complete the missing cells in matrix A?**\n",
        "\n",
        "Suppose that the third user has not rated the tenth item, i.e. $A_{3, 10}$ -> Missing\n",
        "\n",
        "Recall that our underlying assumption for MF based Rec Sys was that $A_{ij} \\approx B_i^T . C_j$\n",
        "\n",
        "We already computed the value for user vector $B_3$, using other ratings that user $U_3$ has given, which can be found in $A_{3, j}$.\n",
        "\n",
        "Similarly, we have value for item vector $C_{10}$, as item $I_{10}$ would've been rated by other users, which can be found in $A_{i, 10}$.\n",
        "\n",
        "So, taking a dot product of $B_3$ and $C_{10}$, can get a very close approximate value of the empty cell $A_{3, 10}$.\n",
        "\n",
        "Similarly, we can fill up all the empty cells in matrix A.\n",
        "\n",
        "> This is the relation between **matrix completion** and **recommender systems**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1tPT40WRqwiE_AZl-MxlJqDiUdWSS0drZ)\n",
        "\n",
        "Lets understand this with context to the optimisation problem, i.e. $min_{B_i, C_j} Σ (A_{ij} - B_i^T . C_j)^2$\n",
        "\n",
        "**Suppose we're trying to find the item vector $C_{10}$**\n",
        "\n",
        "In order to find this, we want to plug-in **ALL** the ratings that item $I_{10}$ has received from different users, i.e. $A_{1, 10}, A_{2, 10}, A_{3, 10}, ..., A_{n, 10}$.\n",
        "\n",
        "Out of these, we use all the ratings that are not NULL/empty.\n",
        "For eg, if $A_{3, 10} = NULL$, it is not included in the optimization problem.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Suppose we're trying to find the user vector $B_{3}$**\n",
        "\n",
        "Similarly, here we plug-in **ALL** ratings that user $U_3$ has given to different products, i.e. $A_{3, 1}, A_{3, 2}, A_{3, 3}, ..., A_{3, m}$.\n",
        "\n",
        "If $A_{3, 2}, A_{3, m} = NULL$, they are not included in the optimization problem.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1CEog1d0CGK0Hsw_nn0W4d8hLx8ukz3g8)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. Is there any failure/boundary case for this?**\n",
        "\n",
        "Yes.\n",
        "\n",
        "Suppose that there is an user, say, $U_{100}$, who hasn't rated even a single item (Cold start or an old user that doesnt rate).\n",
        "\n",
        "This means that all values of 100th row in A would be empty, $A_{100, 1}, A_{100, 2}, A_{100, 3}, ..., A_{100, m} = NULL$\n",
        "\n",
        "Then, it'll be impossible to find the user vector (i.e. $B_{100}$) for him.\n",
        "\n",
        "Similarly, if there's a new item, that has never been rated, even once (cold start), say item $I_{150}$, then $A_{1, 150}, A_{2, 150}, A_{3, 150}, ..., A_{n, 150} = NULL$, and it becomes impossible to find item vector $I_{150}$.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1Kf0ZZnqlYDIK_WWAz3aq2La90eKiRJ2x)\n"
      ],
      "metadata": {
        "id": "fQBNvzn8nORh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **To summarize (Mental Map):**\n",
        "- **Recommendation System** can be formed through **Matrix Completion**, which can be achieved through **Matrix Factorization**, which utilises **Stochastic Gradient Descent**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1qzZNG2re3v-5hSMCzab4BHBNOXYJE2o0)\n"
      ],
      "metadata": {
        "id": "kfP0PQL_8TiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "OqPOAqAFA-BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've studied about PCA in the last few classes. Let's connect how PCA is related to concept of MF.\n",
        "\n",
        "Suppose we have our data matrix, containing **standardised data** $X$ with dimensions `n x d`.\n",
        "\n",
        "Recall that we calculated the **covariance matrix** using X, $S_{d x d}$, which has dimensions `d x d`.\n",
        "\n",
        "Covariance matrix is a square and symmetrix matrix.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How did we calculate the covariance matrix?**\n",
        "\n",
        "Using the relation, $S_{dxd} = \\frac{X_{dxn}^T.X_{nxd}}{n-1}$\n",
        "\n",
        "<br>\n",
        "\n",
        "Before PCA existed, there was this idea called **Eigen Decomposition**, which is a special type of matrix decomposition.\n",
        "\n",
        "> **Q. How can we decompose our covariance matrix using the concept of eigen decomposition?**\n",
        "\n",
        "We can write our $S_{dxd}$ as: $S_{dxd} = W_{dxd} . ∧_{dxd} . W_{dxd}^T$\n",
        "\n",
        "where <br>\n",
        "$W_{dxd}$ -> Matrix where columns represent the `d` **eigen vectors** ($v_1,v_2, v_3, ..., v_d$)<br>\n",
        "$∧_{dxd}$ -> Matrix where all diagonal elements are the **eigen values** ($λ_1, λ_2, λ_3, ..., λ_d$), and all the other elements are 0 <br>\n",
        "$W_{dxd}^T$ -> This is transpose of $W_{dxd}$, so it becomes a matrix where each row represents the transpose of the `d` eigen vectors.\n",
        "\n",
        "**NOTE:**\n",
        "- A property of the singular values in $Σ$ is that: $λ_1>=λ_2>=λ_3>=...>=λ_n$.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **NOTE:**\n",
        "- This is actually how PCA is solved internally, i.e. by decomposing the covariance matrix S as $S_{dxd} = W_{dxd} . ∧_{dxd} . W_{dxd}^T$\n",
        "- During the PCA lecture, it was not discussed how PCA is solved internally.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1z1h-ac7Ub23u6gOQRlHoBXR2NoliOJf1)\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How is PCA different from Matrix Factorization?**\n",
        "\n",
        "It's not. PCA is just a special type of MF.\n",
        "\n",
        "Earlier when we performed MF on $A_{ij}$, we did not care what the decomposing factors $B_i$ and $C_j$ look like, as long as they're satisfying the relation $A_{ij} = B_i^T.C_j$\n",
        "\n",
        "Whereas, in case of PCA, we have constraints on the value of it's decomposed factors.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. What are the constraints on decomposed factors in case of PCA?**\n",
        "\n",
        "Since $W_{dxd}$ consists of eigen vectors, **each column is perpendicular** to other columns.\n",
        "\n",
        "Conversely, each row in $W_{dxd}^T$ is perpendicular to other rows.\n",
        "\n",
        "Also, as we've seen $∧_{dxd}$ is a diagonal matrix.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1LowAgBaXLrR-1vejNwdfYCuWHSStbS6l)"
      ],
      "metadata": {
        "id": "itstBV7aBBH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Singular Value Decomposition (SVD)"
      ],
      "metadata": {
        "id": "Ult5F6KmdC54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "One drawback of using PCA is that it can only be applied on the covariance matrix (S), which is square and symmetric.\n",
        "\n",
        "There is another technique which can help in factorising our data matrix, called **Singular Value Decomposition (SVD)**.\n",
        "\n",
        "SVD doesn't require a square matrix, it can be directly applied on our rectangular data matrix with dimensions `n x d`.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **NOTE:**\n",
        "- We are not going to prove these relations, we're just looking at them\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. What does SVD formulation look like?**\n",
        "\n",
        "Here also, we're trying to decompose the data matrix into product of 3 matrices.\n",
        "\n",
        "$X_{nxd} = U_{nxn}.Σ_{nxd}.V_{dxd}^T$\n",
        "\n",
        "Assuming that number of data points is greater than number of dimensions, i.e. $n > d$, lets break down each of these factors:-\n",
        "\n",
        "- $Σ_{nxd}$: diagonal matrix that contain **d singular values**, and the rest of elements are 0. Notice the dimensions, this is a **rectangular** matrix.\n",
        "\n",
        "- $U_{nxn}$: **Left singular vectors**, i.e. a Square matrix containing the **eigen vectors** of $X_{nxd}.X_{dxn}^T = S'_{nxn}$ (let), stacked along columns\n",
        " - **Note:** $X_{nxd}.X_{dxn}^T$ is not the same as covariance matrix $S_{nxn}$, that was $X_{dxn}^T.X_{nxd}$\n",
        "\n",
        "- $V_{dxd}$: **Right singular values**, i.e. a square matrix containing **eigen vectors** of $X_{dxn}^T.X_{nxd} = S_{nxn}$ covariance matrix, stacked along columns.\n",
        " - **Note:** In SVD formulation, $V_{dxd}$ is transposed, therefore, these eigen vectors become stacked along the rows.\n",
        "\n",
        "\n",
        "> **NOTE:**\n",
        "- Eigenvectors and Eigenvalues are only defined for squared matrices, whereas singular values and singular vectors are defined for rectangular matrices also.\n",
        "- Notice that $V_{dxd}$ becomes exactly same as $W_{dxd}$ that we saw in PCA.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Q. How do we find singular values?**\n",
        "\n",
        "Singular values are related to eigen values as per the following relation:\n",
        "\n",
        "$S_i^2 = λ_i * (n-1)$\n",
        "\n",
        "**NOTE:**\n",
        "- A property of the singular values in $Σ$ is that: $s_1>=s_2>=s_3>=...>=s_n$.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1fhrFTWGMyBtdXyVcy3md1h1YxzZzqAuh)\n",
        "\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1Ny2ihrbM6bwfdWPBY-QCcOVtOpdNx5Ir)\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1rvuRF9hFyEWftAFKv8LpH79xziHAsAUJ)"
      ],
      "metadata": {
        "id": "xGHGw4OmdSIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Q. Why is SVD important for us?**\n",
        "\n",
        "The concept of SVD is very closely related to PCA. However, there is another concept, called `truncated SVD` that is very important.\n",
        "\n",
        "We will study about this shortly.\n",
        "\n",
        "This concept is capable of coming up with very interesting feature engineering, given a data matrix $X_{nxd}$"
      ],
      "metadata": {
        "id": "HuDpiHYZihHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next lecture, we will see other special cases and applications of matrix factorization, and connect all of it to the context of Recommender Systems."
      ],
      "metadata": {
        "id": "CFnZ3hIUj_ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "JYjCn-w5kQgj"
      }
    }
  ]
}